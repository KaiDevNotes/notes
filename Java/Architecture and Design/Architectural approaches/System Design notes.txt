


Books and sources:

[B1]: System Design Interview. Alex Xu. 2nd edition


--------------------------------------------------------
--------------------------------------------------------



* Scaling from zero to millions of users. (B1 ch. 1)

- Keep web tier stateless
- Build redundancy at every tier
- Cache data as much as you can
- Support multiple data centers
- Host static assets in CDN
- Scale your data tier by sharding
- Split tiers into individual services
- Monitor your system and use automation tools



* We should keep a mircoservice stateless in order to be able to scale it horizontally.


* Redundancy is a prerequisite of failover.



* TRANSACTIONAL OUTBOX PATTERN

https://microservices.io/patterns/data/transactional-outbox.html

PROBLEM: 

How to publish messages as part of a database transaction?

E.g. service should read entity from DB, perform some calculations based
on the data from the entity, send calculations result to another service,
update status of the entity and save the entity. All this stuff should be 
performed in one transaction.

SOLUTION: 

Service reads entity from DB, performs some calculations based
on the data from the entity, updates status of the entity and saves the entity.
ALSO the service put a row into another DB table (task for calculations sending) 
during the same DB transaction. Then separate scheduled process of the service 
will take the task and send calculation results to target service making sure 
that calculation results were dilivered successfully to the target service.

  

* Use exponential delay for RETRIES in order to not overload target server 
in case when the server works too slowly at particular moment.


* Use queues (e.g. Kafka) to achieve low coupling between distributed components 
of system and ability to scale the components independently.



* CONSISTENT HASHING (B1 ch. 5)

This approach solves re-hashing problem and is used for load distribution
evenly between several nodes, e.g. data between DB shards or cache nodes.

Re-hashing problem is about re-destribution of data between nodes during up/down
scaling (nodes added/removed), in the same way as HashMap entries should be
redestributed between buckets when number of buckets is increased.



* We should strive to avoid direct access of incoming load (processing of
HTTP requests, messages etc.) to limited resources (cpu, memory, connections in
pools etc.). E.g. if processing of each incoming request requires access to...:

- Relational DB with limited connection pool - in this case we can consider
caching in order to avoid DB access for each request and not exhaust connection
pool, or we can consider usage of NoSQL DB which is optimized for high friquency
access by key.

- 3rd party service via HTTP request - in this case we can consider caching

- Memory (e.g. amount of objects created in memory during request processing
directly depends on a request param value) - in this case we should apply limit
on possible value of such request param and validate the limitation before the
request processing in order to avoid exhausting of heap space and as a result
OutOfMemoryError.



* Validation of input data should be done on server side. Even if validation is
done on client side we should not rely on it.




